{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pm_python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1GKbEiyAw22RtGnJ174Aq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kulbir-ahluwalia/CMSC818B_MiniProject_2/blob/main/python/pm_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhy51H5ixNY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cc271d-031e-4208-94f8-5ac9d81181c1"
      },
      "source": [
        "## Get the required python files\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/pm_env.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/custom_algorithms.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 04:35:59--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5622 (5.5K) [text/plain]\n",
            "Saving to: ‘actors.py’\n",
            "\n",
            "actors.py           100%[===================>]   5.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-04 04:35:59 (68.1 MB/s) - ‘actors.py’ saved [5622/5622]\n",
            "\n",
            "--2020-12-04 04:35:59--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/env.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6874 (6.7K) [text/plain]\n",
            "Saving to: ‘env.py’\n",
            "\n",
            "env.py              100%[===================>]   6.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-04 04:35:59 (72.4 MB/s) - ‘env.py’ saved [6874/6874]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTjxCbRgxYj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5f7e08-076e-4579-a7e2-af2c13c06a08"
      },
      "source": [
        "!pip install pygame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/4c/2ebe8ab1a695a446574bc48d96eb3503649893be8c769e7fafd65fd18833/pygame-2.0.0-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbaTdYq2Nng"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1TnTnUo9-1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa9bd8d-20f6-472c-e7ca-fc195298ad11"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "import time \n",
        "import os, sys\n",
        "import pygame\n",
        "\n",
        "\n",
        "# set SDL to use the dummy NULL video driver, \n",
        "#   so it doesn't need a windowing system.\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 2.0.0 (SDL 2.0.12, python 3.6.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtQb9iil-DZz"
      },
      "source": [
        "## Import classes for elements and visualization\n",
        "from actors import Player, Obstacle, Drone\n",
        "from pm_env import Canvas, process_into_image, process_img, get_obstacles, get_droneview, update_all, process_screen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJloCM75-3Va"
      },
      "source": [
        "### Defining the environement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3rFSyn-F2z"
      },
      "source": [
        "## Canvas is the grid we are going to use\n",
        "canvas = Canvas(300,300)\n",
        "\n",
        "## Create the robots\n",
        "playerList = []\n",
        "playerList.append(Player(pos=[20, 10], color='g', size=10))\n",
        "playerList.append(Player(pos=[0, 260], color='g', size=10))\n",
        "playerList.append(Player(pos=[200, 10], color='g', size=10))\n",
        "playerList.append(Player(pos=[250, 200], color='g', size=10))\n",
        "# playerList.append(Player(pos=[200, 300], color='g', size=10))\n",
        "# playerList.append(Player(pos=[400, 400], color='g', size=10))\n",
        "\n",
        "## Create teh robots at random locations\n",
        "n_obj = 20 # number of objects\n",
        "obstacleList = []\n",
        "# obstacleList.append(Obstacle(pos=[60, 60], size=[10,15]))\n",
        "# obstacleList.append(Obstacle(pos=[60, 60],size=[20,10]))\n",
        "r_coords = np.random.randint(0, canvas.height, (n_obj)) # random rows\n",
        "c_coords = np.random.randint(0, canvas.width, (n_obj)) # random columns\n",
        "# Width and height would be chosen from 10,15,20,25,30 randomly\n",
        "for i in range(len(r_coords)):\n",
        "    obstacleList.append(Obstacle(pos=[r_coords[i], c_coords[i]], \n",
        "                                 size=[np.random.choice([10,15,20,25,30]),np.random.choice([10,15,20,25,30])]))\n",
        "\n",
        "\n",
        "### Add drone to the environememnt\n",
        "droneList = []\n",
        "droneList.append(Drone(pos=[150,150], color='b',  size=100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elzLFt7I_b-_"
      },
      "source": [
        "### Algorithms for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCUTHZ-6-QO0"
      },
      "source": [
        "# pygame.init()\n",
        "\n",
        "## Step size. How many grids would the robot move at each step\n",
        "step_size = playerList[0].size\n",
        "\n",
        "## the dictionary defniing how many to update the location\n",
        "move_dict = {\n",
        "    'left' : np.array([0, -step_size]),\n",
        "    'up' : np.array([-step_size,0]),\n",
        "    'right' : np.array([0, step_size]),\n",
        "    'down' : np.array([step_size,0])\n",
        "}\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtiZ9cyt_hz4"
      },
      "source": [
        "#### Lawnmower algorithm with *hover over buildings*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyuOMywb_ann"
      },
      "source": [
        "## Order of moves for anti-clockwise movement\n",
        "anti_clock_order_dict = {'up' : 0,\n",
        "                    'right': 1,\n",
        "                    'down' : 2,\n",
        "                    'left': 3}\n",
        "anti_clock_order = ['down', 'right', 'up', 'left']\n",
        "\n",
        "## Function to check if a location is valid (within grid)\n",
        "def is_valid(pos, limits):\n",
        "    if ((pos[0] < 0) or (pos[1] < 0) or (pos[0] >= limits[0]) or (pos[1] >= limits[1])):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "## The lawnmower algorithm\n",
        "def lawn_mover(player, data_img):\n",
        "    pos = player.pos  # Get players location\n",
        "    obstacle = (data_img[:,:,0] > 0).astype(int) # get grid indicating where objects are\n",
        "    covered = (data_img[:,:,1] > 0).astype(int) # get grid indicating which areas have been covered\n",
        "    # covered[data_img[:,:,1] == 255] = 0\n",
        "\n",
        "    # if the last action is not recorded, move to left or right as per the row\n",
        "    if player.prev_action == None:\n",
        "        player.prev_action = ['right', 'left'][pos[1]%2]\n",
        "    \n",
        "\n",
        "    ####\n",
        "    ## Iterate over each direction, till yu find a valid orientation to move\n",
        "    for i in range(4):\n",
        "        player.prev_action = anti_clock_order[(anti_clock_order_dict[player.prev_action]+i) %4]\n",
        "        move = move_dict[player.prev_action]\n",
        "        print('CHECK: ', pos, move, player.prev_action)\n",
        "        temp_pos = pos + move\n",
        "        if not is_valid(temp_pos, data_img.shape[:2]):\n",
        "            continue\n",
        "        else:\n",
        "            if (covered[temp_pos[0], temp_pos[1]] == 1):# or (obstacle[temp_pos[0], temp_pos[1]] == 1):\n",
        "            # if (obstacle[temp_pos[0], temp_pos[1]] == 1):\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "    return temp_pos\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1S3UyJ_aZA"
      },
      "source": [
        "#### Greedy movement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYvQCiq--7j"
      },
      "source": [
        "## Greedy algorithm (distributed)\n",
        "def greedy_algorithm(player, data_img):\n",
        "    pos = player.pos #get player location\n",
        "    obstacle = data_img[:,:,2].astype(int) # get grid indicating where objects are\n",
        "    covered = (data_img[:,:,1]).astype(int) # get grid indicating which areas have been covered and how much latency is there\n",
        "    # covered[data_img[:,:,1] == 255] = 0\n",
        "    cost_grid = obstacle*10 + covered # give high cost to obstacles\n",
        "\n",
        "    # if the last action is not recorded, move to left or right as per the row\n",
        "    action_list = ['right', 'down', 'left', 'up']\n",
        "    if player.prev_action == None:\n",
        "        player.prev_action = ['right', 'left'][pos[0]%2]\n",
        "\n",
        "\n",
        "    #######\n",
        "    ## Looks into future move for all 4 directions, move whereever robot would have least cost\n",
        "    temp_action_list = []\n",
        "    temp_cost_list = []\n",
        "    for i in range(4):\n",
        "        new_action = action_list[ (action_list.index(player.prev_action) + i) % 4 ]\n",
        "        move = move_dict[ new_action ]\n",
        "        \n",
        "        temp_pos = pos + move\n",
        "        # print('CHECK: ', pos, temp_pos, new_action)\n",
        "        if not is_valid(temp_pos, data_img.shape[:2]):\n",
        "            # print('NOT Valid: ', pos, temp_pos)\n",
        "            temp_action_list.append(new_action)\n",
        "            temp_cost_list.append(50000)\n",
        "            # continue\n",
        "        else:\n",
        "            # if (covered[temp_pos[0], temp_pos[1]] == 1) or (obstacle[temp_pos[0], temp_pos[1]] == 1):\n",
        "            temp_action_list.append(new_action)\n",
        "            temp_cost = np.sum(cost_grid[max(0,temp_pos[0]-player.size):min(temp_pos[0]+player.size, data_img.shape[0]), \n",
        "                                         max(0, temp_pos[1]-player.size): min(temp_pos[1]+player.size,data_img.shape[1])])\n",
        "            temp_cost_list.append(temp_cost)\n",
        "\n",
        "                # print('OCCUPIED: ', covered[temp_pos[0], temp_pos[1]], obstacle[temp_pos[0], temp_pos[1]] )\n",
        "            #     continue\n",
        "            # else:\n",
        "            #     break\n",
        "\n",
        "    # print('Costs: ', temp_cost_list)\n",
        "    # print('Actions: ', temp_action_list)\n",
        "\n",
        "    # Choose next action based on where the cost would be least\n",
        "    new_action = temp_action_list[np.argmin(temp_cost_list)]\n",
        "    temp_pos = pos + move_dict[ new_action ]\n",
        "\n",
        "    # update last action\n",
        "    player.prev_action = new_action\n",
        "    \n",
        "    # if teh move is not valid, do not move\n",
        "    if not is_valid(temp_pos, data_img.shape[:2]):\n",
        "        temp_pos = pos\n",
        "        \n",
        "    return temp_pos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bYqi6N-KPb"
      },
      "source": [
        "### Envoronemtn image as a numpy array\n",
        "data_img = np.zeros(canvas.grid.shape+(3,))\n",
        "# data_img = init_env(canvas, playerList, obstacleList, droneList)\n",
        "### Coverage information\n",
        "coverage = np.zeros(canvas.grid.shape, dtype=np.uint8)\n",
        "#### Drone Map\n",
        "drone_map = np.zeros(canvas.grid.shape+(3,), dtype=np.uint8)\n",
        "## Run for 300 iterations\n",
        "latency_factor = 2\n",
        "for i in range(300):\n",
        "\n",
        "    ### Get next location for each robot\n",
        "    for player in playerList:\n",
        "        # player.pos = lawn_mover(player, data_img)\n",
        "        player.pos = greedy_algorithm(player, data_img)\n",
        "        # player.move(np.random.choice(['up', 'down', 'left', 'right']), player.size, canvas)\n",
        "\n",
        "\n",
        "    for drone in droneList:\n",
        "         drone.move(np.random.choice(['up', 'down', 'left', 'right']), drone.size//10, canvas)   \n",
        "\n",
        "    update_all(canvas, playerList, obstacleList, droneList) \n",
        "\n",
        "\n",
        "    covergae, data_img = process_screen(my_coverage=coverage, my_canvas=canvas)\n",
        "    obstacle_map = get_obstacles(data_img)\n",
        "    \n",
        "    # drone_map = get_droneview(drone_map, data_img, latency_factor)\n",
        "    drone_map = get_droneview(drone_map, data_img, latency_factor, droneList)\n",
        "    #Display image, clear cell every 0.5 seconds\n",
        "    #convert image so it can be displayed in OpenCV\n",
        "    ## UNCOMMENT IN CASE OF ISSUE\n",
        "    # view = pygame.surfarray.array3d(canvas.screen)\n",
        "    \n",
        "    #  convert from (width, height, channel) to (height, width, channel)\n",
        "    ## UNCOMMENT  NEXT 2 LINES IN CASE OF ERROR\n",
        "    # view = view.transpose([1, 0, 2])\n",
        "    # img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # cv2_imshow(data_img) #img_bgr[yv, xv])\n",
        "    print('\\t\\t Environment \\t\\t\\t Drone View ')\n",
        "    cv2_imshow(np.hstack([data_img, drone_map]))\n",
        "    print('\\t\\t Coverage \\t\\t\\t Obstacles ')\n",
        "    cv2_imshow(np.hstack([coverage, 255*obstacle_map]))\n",
        "    \n",
        "\n",
        "    ## Wait 0.1 second before running next iteration\n",
        "    time.sleep(0.1)\n",
        "    output.clear()\n",
        "\n",
        "    # if i == 3:\n",
        "    #     break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oChiLXbJUUdJ"
      },
      "source": [
        "## Gym like Env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZ0pOWcUUIM",
        "outputId": "ad6f7fb4-c2dc-4e5d-94c6-aed1eda28951"
      },
      "source": [
        "## Get the required python files\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/pm_env.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/custom_algorithms.py\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-05 15:30:41--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5622 (5.5K) [text/plain]\n",
            "Saving to: ‘actors.py’\n",
            "\n",
            "\ractors.py             0%[                    ]       0  --.-KB/s               \ractors.py           100%[===================>]   5.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-05 15:30:41 (72.5 MB/s) - ‘actors.py’ saved [5622/5622]\n",
            "\n",
            "--2020-12-05 15:30:41--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/pm_env.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6874 (6.7K) [text/plain]\n",
            "Saving to: ‘pm_env.py’\n",
            "\n",
            "pm_env.py           100%[===================>]   6.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-05 15:30:41 (76.1 MB/s) - ‘pm_env.py’ saved [6874/6874]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0rXabCECEm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305370f8-d0cc-4150-ea6c-a3ea3999ca79"
      },
      "source": [
        "!pip install gym\n",
        "!pip install pygame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E83rv_WjDzHh"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBorTJq8Ugg8"
      },
      "source": [
        "import gym\n",
        "from gym import spaces"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQWaZjwGUnzW",
        "outputId": "3f172087-b699-4c47-92b5-6f820a72dc18"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "import time \n",
        "import os, sys\n",
        "import pygame\n",
        "\n",
        "\n",
        "# set SDL to use the dummy NULL video driver, \n",
        "#   so it doesn't need a windowing system.\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 2.0.0 (SDL 2.0.12, python 3.6.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXOUZ8WHUnlO"
      },
      "source": [
        "## Import classes for elements and visualization\n",
        "from actors import Player, Obstacle, Drone\n",
        "from pm_env import Canvas, process_into_image, process_img, get_obstacles, get_droneview, update_all, process_screen"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIxnFshV0fu"
      },
      "source": [
        "### Greedy Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTfv8Z2PVz_s"
      },
      "source": [
        "# pygame.init()\n",
        "\n",
        "## Step size. How many grids would the robot move at each step\n",
        "step_size = 10\n",
        "\n",
        "## the dictionary defniing how many to update the location\n",
        "move_dict = {\n",
        "    'left' : np.array([0, -step_size]),\n",
        "    'up' : np.array([-step_size,0]),\n",
        "    'right' : np.array([0, step_size]),\n",
        "    'down' : np.array([step_size,0])\n",
        "}\n",
        "\n",
        "## Function to check if a location is valid (within grid)\n",
        "def is_valid(pos, limits):\n",
        "    if ((pos[0] < 0) or (pos[1] < 0) or (pos[0] >= limits[0]) or (pos[1] >= limits[1])):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "## Greedy algorithm (distributed)\n",
        "def greedy_algorithm(player, data_img):\n",
        "    pos = player.pos #get player location\n",
        "    obstacle = data_img[:,:,2].astype(int) # get grid indicating where objects are\n",
        "    covered = (data_img[:,:,1]).astype(int) # get grid indicating which areas have been covered and how much latency is there\n",
        "    # covered[data_img[:,:,1] == 255] = 0\n",
        "    cost_grid = obstacle*10 + covered # give high cost to obstacles\n",
        "\n",
        "    # if the last action is not recorded, move to left or right as per the row\n",
        "    action_list = ['right', 'down', 'left', 'up']\n",
        "    if player.prev_action == None:\n",
        "        player.prev_action = ['right', 'left'][pos[0]%2]\n",
        "\n",
        "\n",
        "    #######\n",
        "    ## Looks into future move for all 4 directions, move whereever robot would have least cost\n",
        "    temp_action_list = []\n",
        "    temp_cost_list = []\n",
        "    for i in range(4):\n",
        "        new_action = action_list[ (action_list.index(player.prev_action) + i) % 4 ]\n",
        "        move = move_dict[ new_action ]\n",
        "        \n",
        "        temp_pos = pos + move\n",
        "        # print('CHECK: ', pos, temp_pos, new_action)\n",
        "        if not is_valid(temp_pos, data_img.shape[:2]):\n",
        "            # print('NOT Valid: ', pos, temp_pos)\n",
        "            temp_action_list.append(new_action)\n",
        "            temp_cost_list.append(50000)\n",
        "            # continue\n",
        "        else:\n",
        "            # if (covered[temp_pos[0], temp_pos[1]] == 1) or (obstacle[temp_pos[0], temp_pos[1]] == 1):\n",
        "            temp_action_list.append(new_action)\n",
        "            temp_cost = np.sum(cost_grid[max(0,temp_pos[0]-player.size):min(temp_pos[0]+player.size, data_img.shape[0]), \n",
        "                                         max(0, temp_pos[1]-player.size): min(temp_pos[1]+player.size,data_img.shape[1])])\n",
        "            temp_cost_list.append(temp_cost)\n",
        "\n",
        "\n",
        "    # Choose next action based on where the cost would be least\n",
        "    new_action = temp_action_list[np.argmin(temp_cost_list)]\n",
        "    temp_pos = pos + move_dict[ new_action ]\n",
        "\n",
        "    # update last action\n",
        "    player.prev_action = new_action\n",
        "    \n",
        "    # if teh move is not valid, do not move\n",
        "    if not is_valid(temp_pos, data_img.shape[:2]):\n",
        "        temp_pos = pos\n",
        "        \n",
        "    return temp_pos\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhEwjd0HV1V4"
      },
      "source": [
        "### Environment Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3kymvswEZTN"
      },
      "source": [
        "N_DISCRETE_ACTIONS = 4"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siC8SyiUD6uv"
      },
      "source": [
        "\n",
        "class PMGridEnv(gym.Env):\n",
        "  \"\"\"Custom Environment that follows gym interface\"\"\"\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self, height, width, robot_info, drone_info, num_obstacles, drone_latency):\n",
        "    super(PMGridEnv, self).__init__()\n",
        "    # Define action and observation space\n",
        "    self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
        "    # using image as input (can be channel-first or channel-last):\n",
        "    self.observation_space = spaces.Box(low=0, high=255,\n",
        "                                        shape=(height, width, 3), dtype=np.uint8)\n",
        "\n",
        "    # To convert integer actions into string\n",
        "    self.action_list = ['up', 'down', 'left', 'right']\n",
        "\n",
        "    ## Canvas is the grid we are going to use\n",
        "    self.canvas = Canvas(height, width)\n",
        "\n",
        "    self.latency_factor = drone_latency\n",
        "\n",
        "    ## Create the robots\n",
        "    self.playerList = []\n",
        "    for i in range(len(robot_info)//3):\n",
        "        x_loc, y_loc, size = robot_info[3*i : 3*(i+1)]\n",
        "        self.playerList.append(Player(pos=[x_loc, y_loc], color='g', size=size))    \n",
        "    \n",
        "    ### Add drone to the environememnt\n",
        "    self.droneList = []\n",
        "    for i in range(len(drone_info)//3):\n",
        "        x_loc, y_loc, size = drone_info[3*i : 3*(i+1)]\n",
        "        self.droneList.append(Drone(pos=[x_loc, y_loc], color='b',  size=size))\n",
        "\n",
        "    ## Create the obstacle at random locations\n",
        "    self.n_obj = num_obstacles # number of objects\n",
        "    self.obstacleList = []\n",
        "    r_coords = np.random.randint(0, self.canvas.height, (self.n_obj)) # random rows\n",
        "    c_coords = np.random.randint(0, self.canvas.width, (self.n_obj)) # random columns\n",
        "    # Width and height would be chosen from 10,15,20,25,30 randomly\n",
        "    for i in range(len(r_coords)):\n",
        "        self.obstacleList.append(Obstacle(pos=[r_coords[i], c_coords[i]], \n",
        "                                    size=[np.random.choice([10,15,20,25,30]),\n",
        "                                          np.random.choice([10,15,20,25,30])]))\n",
        "\n",
        "    ### Environement image as a numpy array\n",
        "    self.env_img   = np.zeros(self.canvas.grid.shape+(3,), dtype=np.uint8)\n",
        "    ### Coverage information\n",
        "    self.coverage  = np.zeros(self.canvas.grid.shape, dtype=np.uint8)\n",
        "    ### Obstacle map information\n",
        "    self.obstacle_map = np.zeros(self.canvas.grid.shape, dtype=np.uint8)\n",
        "    #### Drone Map\n",
        "    self.drone_map = np.zeros(self.canvas.grid.shape+(3,), dtype=np.uint8)\n",
        "    #### Saving initial state for resets\n",
        "    self.inital_state = [self.playerList.copy(), self.droneList.copy(), self.obstacleList.copy()]\n",
        "\n",
        "    ### Update entites in screen\n",
        "    self.update_all() \n",
        "    self.process_screen()\n",
        "\n",
        "  def step(self, action):\n",
        "    ### Update robots' locations\n",
        "    for player in self.playerList:\n",
        "        # player.pos = lawn_mover(player, data_img)\n",
        "        player.pos = greedy_algorithm(player, self.env_img)\n",
        "        # player.move(np.random.choice(['up', 'down', 'left', 'right']), player.size, canvas)\n",
        "\n",
        "    ### Update drones' locations\n",
        "    for drone in self.droneList:\n",
        "         drone.move(self.action_list[action], drone.size//10, self.canvas)\n",
        "\n",
        "    ### Update graphics\n",
        "    self.update_all() \n",
        "    \n",
        "    ### Get updated coverage and observations\n",
        "    # self.covergae, self.env_img = self.process_screen(my_coverage=self.coverage, my_canvas=self.canvas)\n",
        "    self.process_screen()\n",
        "    '''\n",
        "    ## Get obstacle info\n",
        "    self.obstacle_map = self.get_obstacles(self.env_img)\n",
        "    '''\n",
        "    ### Get drone's view\n",
        "    self.drone_map = self.get_droneview(self.drone_map, self.env_img)\n",
        "    \n",
        "    ### Reward coverage from the drone's view\n",
        "    drone_coverage = self.get_coverage(self.drone_map)\n",
        "    drone_coverage = drone_coverage/255.0\n",
        "    reward = np.sum(drone_coverage)\n",
        "\n",
        "    # Persistent monitoring never stops\n",
        "    done = False\n",
        "\n",
        "    # No info as of now\n",
        "    info = None\n",
        "\n",
        "    # # observation is same as the environment image\n",
        "    # observation = self.env_img\n",
        "\n",
        "    # observation is same as the drone image\n",
        "    observation = self.drone_map\n",
        "\n",
        "\n",
        "    return observation, reward, done, info\n",
        "\n",
        "  def reset(self):\n",
        "    self.playerList, self.droneList, self.obstacleList = self.inital_state\n",
        "    \n",
        "    self.process_screen()\n",
        "\n",
        "    return self.env_img  # reward, done, info can't be included\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    output.clear()\n",
        "    vertical_var = np.full((self.env_img.shape[0],10,3), 128, dtype=np.uint8)\n",
        "    # cv2_imshow(data_img) #img_bgr[yv, xv])\n",
        "    print('\\t\\t Environment \\t\\t\\t Drone View ')\n",
        "    cv2_imshow(np.hstack([self.env_img, vertical_var, self.drone_map]))\n",
        "    # print('\\t\\t Coverage \\t\\t\\t Obstacles ')\n",
        "    # cv2_imshow(np.hstack([self.coverage, 255*self.obstacle_map]))\n",
        "    print('\\t\\t Coverage \\t\\t\\t Drone Coverage ')\n",
        "    cv2_imshow(np.hstack([self.coverage, vertical_var[:,:,0], self.drone_map[:,:,1]]))\n",
        "\n",
        "\n",
        "  def close (self):\n",
        "    pygame.close()\n",
        "\n",
        "  def get_action_space(self):\n",
        "      return self.action_space\n",
        "\n",
        "  def update_all(self):\n",
        "    ## Update the environment\n",
        "    patch = self.canvas.update()\n",
        "    \n",
        "    ## Update the drone\n",
        "    for drone in self.droneList:\n",
        "        patch = drone.update(self.canvas)\n",
        "    \n",
        "    ## Update the robot locations\n",
        "    for player in self.playerList:\n",
        "        patch = player.update(self.canvas)\n",
        "\n",
        "    ## Update the obstacles\n",
        "    for obstacle in self.obstacleList:\n",
        "        patch = obstacle.update(self.canvas)  \n",
        "\n",
        "\n",
        "  def process_into_image(self):\n",
        "    grid = self.canvas.grid.copy()\n",
        "    player_area = np.zeros(self.canvas.grid.shape, dtype=int)\n",
        "    obstacle_area = np.zeros(self.canvas.grid.shape, dtype=int)\n",
        "    drone_area =  np.zeros(self.canvas.grid.shape, dtype=int)\n",
        "\n",
        "    for player in self.playerList:\n",
        "        radius = player.size\n",
        "        center = player.pos\n",
        "\n",
        "        xv, yv = np.meshgrid(range(-radius, radius+1), range(-radius, radius+1), sparse=False, indexing='ij')\n",
        "        valid_array = (xv**2 + yv**2 <= radius**2).astype(int)\n",
        "        \n",
        "        pos_array =  np.stack([xv, yv], axis=-1) + center\n",
        "\n",
        "        r_ind_min = max(0, -(center[0]-radius))\n",
        "        c_ind_min = max(0, -(center[1]-radius))\n",
        "\n",
        "        if center[0]+radius+1 <= self.canvas.width:\n",
        "            r_ind_max = 2*radius+1\n",
        "        else:\n",
        "            r_ind_max = -(center[0]+radius -self.canvas.width)-1\n",
        "        \n",
        "        if center[1]+radius+1 <= self.canvas.width:\n",
        "            c_ind_max = 2*radius+1\n",
        "        else:\n",
        "            c_ind_max = -(center[1]+radius - self.canvas.height)-1\n",
        "        \n",
        "        player_area[max(0, center[0]-radius) : min(center[0]+radius+1, self.canvas.width), \n",
        "                    max(0, center[1]-radius) : min(center[1]+radius+1, self.canvas.height)] = valid_array[r_ind_min:r_ind_max, c_ind_min:c_ind_max]\n",
        "        \n",
        "        \n",
        "    for obstacle in self.obstacleList:\n",
        "        corner = obstacle.pos\n",
        "        dimensions = obstacle.size\n",
        "        \n",
        "        obstacle_area[corner[0]:corner[0]+dimensions[0], corner[1]-dimensions[1]:corner[1]] = 1\n",
        "\n",
        "    for drone in self.droneList:\n",
        "        corner = drone.pos\n",
        "        dimensions = drone.size\n",
        "\n",
        "        center = corner - dimensions//2\n",
        "        \n",
        "        drone_area[center[0]:center[0] + dimensions, center[1] - dimensions :center[1]] = 1\n",
        "\n",
        "    return grid*0 + player_area*1 + obstacle_area * 2 + drone_area *3\n",
        "\n",
        "  def process_img(self, coverage, img_bgr):\n",
        "    drone_cover = img_bgr[:,:,0]\n",
        "    \n",
        "    coverage[coverage > 0] -= 5\n",
        "    coverage[coverage < 0] = 0\n",
        "    coverage[img_bgr[:,:,1] == 255] = 255\n",
        "\n",
        "    obstacle = img_bgr[:,:,2]\n",
        "\n",
        "    data_img = np.stack([drone_cover, coverage, obstacle], axis=2)\n",
        "    return data_img, coverage\n",
        "\n",
        "  def process_screen(self):\n",
        "    ### Create the images\n",
        "    pygame.display.flip()\n",
        "    \n",
        "    #convert image so it can be displayed in OpenCV\n",
        "    view = pygame.surfarray.array3d(self.canvas.screen)\n",
        "    #  convert from (width, height, channel) to (height, width, channel)\n",
        "    view = view.transpose([1, 0, 2])\n",
        "\n",
        "    #  convert from rgb to bgr\n",
        "    img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "    # Convert from x-y format to row-column format and get images as numpy array\n",
        "    xv, yv = np.meshgrid(range(img_bgr.shape[0]), range(img_bgr.shape[1]), indexing='ij')\n",
        "    self.env_img, self.coverage = self.process_img(self.coverage, img_bgr[yv, xv])\n",
        "    \n",
        "     ## Clip the values to void overflow\n",
        "    self.env_img = np.clip(img_bgr[yv, xv].astype(int) + self.env_img.astype(int), a_min=0, a_max=255)\n",
        "    \n",
        "    ## Update pygame environemnt\n",
        "    surf = pygame.surfarray.make_surface(self.env_img)\n",
        "    self.canvas.screen.blit(surf, (0, 0))\n",
        "    \n",
        "    ## Convert data type from int to bytes\n",
        "    self.env_img = self.env_img.astype(np.uint8)\n",
        "\n",
        "  def get_coverage(self, img_bgr):\n",
        "    return img_bgr[:,:,1].astype(int)\n",
        "\n",
        "  def get_obstacles(self, img_bgr):\n",
        "    return (img_bgr[:,:,2] > 0).astype(int)\n",
        "\n",
        "  def get_droneview(self, drone_map, img_bgr):\n",
        "    prev_map = drone_map.astype(int)\n",
        "    drone_map = np.clip(prev_map-self.latency_factor, 0, 255).astype(np.uint8)\n",
        "    \n",
        "    for drone in self.droneList:\n",
        "        drone_map[drone.pos[0]:drone.pos[0]+drone.size, drone.pos[1]:drone.pos[1]+drone.size,1:] = img_bgr[drone.pos[0]:drone.pos[0]+drone.size, drone.pos[1]:drone.pos[1]+drone.size,1:]\n",
        "   \n",
        "    return drone_map"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3DPaOA0REOc"
      },
      "source": [
        "### Running with environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlFdPTNzNIuZ"
      },
      "source": [
        "height, width = 300, 300\n",
        "robot_info = [20, 10, 10, 0, 260, 10, 200, 10, 10, 250, 200, 10]\n",
        "drone_info = [150, 150, 100]\n",
        "num_obstacles = 40 # number of objects\n",
        "drone_latency = 2\n",
        "\n",
        "env = PMGridEnv(height, width, robot_info, drone_info, num_obstacles, drone_latency)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DlSckRYzNJ9b",
        "outputId": "4db5e933-da48-4078-8e48-3866559c4e7f"
      },
      "source": [
        "for i in range(300):\n",
        "    observation, reward, done, info = env.step(1)\n",
        "    print(reward)\n",
        "    env.render()\n",
        "    time.sleep(0.1)\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t Environment \t\t\t Drone View \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=610x300 at 0x7FC8AC943320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\t\t Coverage \t\t\t Drone Coverage \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=610x300 at 0x7FC8AC943DD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5d5123b61f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-065bfa57ce8e>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m### Get updated coverage and observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# self.covergae, self.env_img = self.process_screen(my_coverage=self.coverage, my_canvas=self.canvas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     '''\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m## Get obstacle info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-065bfa57ce8e>\u001b[0m in \u001b[0;36mprocess_screen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m      \u001b[0;31m## Clip the values to void overflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bgr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m## Update pygame environemnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6F4RsiB8RgmD",
        "outputId": "f3d59d07-86d6-4a0b-86b2-edbf16f99061"
      },
      "source": [
        "env.reset()\n",
        "cv2_imshow(env.env_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAFZ0lEQVR4nO3d207iUBiA0ULm/V/ZuTAmGgRp2eXrYa1LxygyfPw9bNrLBOfxcf+fLs99wwr+rfWDYV8e5Leya/abgWmaRMi5LN6kXG1bdBIh5ETIySyYaWuOwUmEnNGsqFYucBIhJ/VkWusXOImQ8/ozsLcU+MbfA5t1e4bwvVnc+W31w4LzuGnr8boBKcJoP/cJ/1y50y3tgaP6FuGTgekQhvqKcFZaOoRxrtO0KCodwiA+ysSJDJwdA49RXpc/LsMQRrBiBmIPI7w4MQirMwkh9vDAjL0+WJ9JCLHrNq+6AedhEkLsOk1bvOoGnMfXJNzYVTfgPL5tjm7pqhtwHj/3CTdz1Q04j5vzhPduiyE/WMedk/WSg3dxigJiIoSYCCEmQoiJEGIihJgIISZCiIkQYiIEAAAAAAAAAAAAAAAAAAAAADiuk95+6fbWb4ud9BlknDu3RoP9ePyWuv13SVdbg5gIIbanzdGBO3KwHSYhxEQIMRFCTIQQEyHERAgxEUJMhBATIcT2tGJm4Epci2/Yjj1FOND2V9ZzHjZHISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADiGS/JbP8b9qOYPgHHcGg1iIoSYCCEmQoiJEGIihJgIISZCiP2rHwCnZtnGZBJCToQQEyHERAgxEUJMhBATIcRECDERQkyEEBMhxEQIMRFCTIQQEyHERAgxEUJMhBATIcRcY2bvPq/SstcLrOz1cQ/lSdi7gZdKOoMtvuBtju7dFl9VzCJCiIkQYiKEmAghJkKIiRBiIoSYCCF29mVrr6w3cZqcIUxCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYiKEmAghJkKIiRBiIoTY2a8x4zox5ExCiIkQYiKEmAghJkKIiRBiIoSYCCEmQojdWTFze7MiS0tgHTcR3rtX2OfXpQij/dwc/fNufa/czg/4zbcInwxMhzDUV4Sz0tIhjHOdpkVR6RAGcYoCYtflM80whBFMQog9jPDixCCsziSE2MMLPdnrg/WZhBC7Lt/rs7sIIxzquqPrbT57w2E912la9BLzqoRBvvYJZ0WlQBjn24GZJ9NSIAz18+jon4EpEEa7OTDzmZnLW8C73Dk6Kjl4FyfrISZCiIkQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGKH+mQ9m/Wx2nLky/6vR2YSQuxQk9BnP9gjkxBiIoSYCCEmQoiJEGIihJgIIebU2gHsfsnIG23xBW8SQkyEEDvUsrX1zNrg2+IWDxtmEkJMhBATIcTsE3J8sz5S/Phb1zgdJEKG+rh5DV+cxvyDCBnkNr/vX5fiffYJGeFegc9/w4mNnIQD3+v8j+3Jk4F9XMzDX5mEvGbWiDMPfyNCXrAgKh3eECHERMhSi2eaYfiTCCHmPOF4rx8B3P2k+PwDHAp9jggPYI/N7vExr0WErMAMnMM+IcREyFKLtyhtiv4kQojZJ3zKr+/ddnymy/xnwRi8YRLymllRKfA3R56Er0wqr5YZnpyHntM7jhwh7/Nnh78V6EKSn0TIIPdWyRyrnjX+GhEy1LGSew8HZiAmQoiN3By1JQIL2CdczpsOQ9gchZgIISZCiIkQYg7McHyvHEKbvxpvNpMQYiKEmAghJkKIiRBiIoSYCCEmQoiJEGIihJgIISZCiIkQYj5FQcb1QT6JEB55wzuFCImtd3OrvUxa+4QQO/Ik3MsbISdnEkJMhBATIcRECDERQkyEEDvyKYojGXhG25mbrTEJISZCiIkQYtvaJ7SWlxMyCSH2H2puU2rpBhIRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x300 at 0x7F694C6D7208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjNKi4aPSraK"
      },
      "source": [
        "# PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUDmhw3n8gZK"
      },
      "source": [
        "Getting files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeyExiZ-8fdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2d7226-88ff-4a95-f57e-e7320f707f54"
      },
      "source": [
        "## Get the required python files\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/pm_env.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/PPO_agent.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/constants.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/Train.py\n",
        "!wget https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/custom_algorithms.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 00:21:05--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/actors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5622 (5.5K) [text/plain]\n",
            "Saving to: ‘actors.py.1’\n",
            "\n",
            "\ractors.py.1           0%[                    ]       0  --.-KB/s               \ractors.py.1         100%[===================>]   5.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-06 00:21:05 (65.9 MB/s) - ‘actors.py.1’ saved [5622/5622]\n",
            "\n",
            "--2020-12-06 00:21:05--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/pm_env.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15896 (16K) [text/plain]\n",
            "Saving to: ‘pm_env.py.1’\n",
            "\n",
            "pm_env.py.1         100%[===================>]  15.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-06 00:21:05 (141 MB/s) - ‘pm_env.py.1’ saved [15896/15896]\n",
            "\n",
            "--2020-12-06 00:21:06--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/PPO_agent.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12479 (12K) [text/plain]\n",
            "Saving to: ‘PPO_agent.py’\n",
            "\n",
            "PPO_agent.py        100%[===================>]  12.19K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-12-06 00:21:06 (14.7 MB/s) - ‘PPO_agent.py’ saved [12479/12479]\n",
            "\n",
            "--2020-12-06 00:21:06--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/constants.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232 [text/plain]\n",
            "Saving to: ‘constants.py.1’\n",
            "\n",
            "constants.py.1      100%[===================>]     232  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-06 00:21:06 (14.1 MB/s) - ‘constants.py.1’ saved [232/232]\n",
            "\n",
            "--2020-12-06 00:21:06--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/Train.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4118 (4.0K) [text/plain]\n",
            "Saving to: ‘Train.py.1’\n",
            "\n",
            "Train.py.1          100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-06 00:21:06 (72.2 MB/s) - ‘Train.py.1’ saved [4118/4118]\n",
            "\n",
            "--2020-12-06 00:21:06--  https://raw.githubusercontent.com/kulbir-ahluwalia/CMSC818B_MiniProject_2/main/python/custom_algorithms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2681 (2.6K) [text/plain]\n",
            "Saving to: ‘custom_algorithms.py.1’\n",
            "\n",
            "custom_algorithms.p 100%[===================>]   2.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-06 00:21:06 (69.5 MB/s) - ‘custom_algorithms.py.1’ saved [2681/2681]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE_P55xVZoDh",
        "outputId": "60927056-40a2-4836-89b6-072fc5f2fb35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pygame\n",
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jatfCzMbWgBS"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "import time \n",
        "import os, sys\n",
        "\n",
        "# set SDL to use the dummy NULL video driver, \n",
        "#   so it doesn't need a windowing system.\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlF_0xI08tZ_",
        "outputId": "e559c754-d8d5-4f5d-820e-50925cb0327e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from PPO_agent import *\n",
        "from pm_env import PMGridEnv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 2.0.0 (SDL 2.0.12, python 3.6.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeojcIB189_N"
      },
      "source": [
        "# from Train import *\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcuJz1PgiQvP",
        "outputId": "77a87707-a53e-4ddb-c7ea-f3206726a98d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "# from env import Env\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "from time import time as t\n",
        "\n",
        "\n",
        "### change name from pp_agent to PPO_agent\n",
        "### chnage line 79 to use .n instead of length\n",
        "from PPO_agent import PPO\n",
        "from PPO_agent import Memory\n",
        "from constants import CONSTANTS\n",
        "\n",
        "CONST = CONSTANTS()\n",
        "\n",
        "np.set_printoptions(threshold=np.inf, linewidth=1000, precision=3, suppress=True)\n",
        "\n",
        "\n",
        "\n",
        "# env = Env()\n",
        "height, width = 300, 300\n",
        "robot_info = [20, 10, 10, 0, 260, 10, 200, 10, 10, 250, 200, 10]\n",
        "drone_info = [150, 150, 100]\n",
        "num_obstacles = 40 # number of objects\n",
        "drone_latency = 2\n",
        "\n",
        "env = PMGridEnv(height, width, robot_info, drone_info, num_obstacles, drone_latency)\n",
        "\n",
        "memory = Memory(CONST.NUM_AGENTS)\n",
        "rlAgent = PPO(env)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Dir: tf_log/demo_CNN84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqdPo25hXK76"
      },
      "source": [
        "### PPO Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVpBWq569o1t"
      },
      "source": [
        "\n",
        "NUM_EPISODES = 30000\n",
        "LEN_EPISODES = 1000\n",
        "UPDATE_TIMESTEP = 1000\n",
        "curState = []\n",
        "newState = []\n",
        "reward_history = []\n",
        "agent_history_dict = defaultdict(list)\n",
        "totalViewed = []\n",
        "dispFlag = False\n",
        "\n",
        "# curRawState = env.reset()\n",
        "# curState = rlAgent.formatInput(curRawState)\n",
        "# rlAgent.summaryWriter_showNetwork(curState[0])\n",
        "\n",
        "keyPress = 0\n",
        "timestep = 0\n",
        "loss = None\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-GF8utTivyw",
        "outputId": "2613f578-eaa3-456c-fe85-593b1245a341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "\n",
        "for episode in tqdm(range(NUM_EPISODES)):\n",
        "    curRawState = env.reset()\n",
        "\n",
        "    # generate state for each agent\n",
        "    # curState = rlAgent.formatInput(curRawState)\n",
        "    curState = np.transpose(curRawState, (2,0,1))[np.newaxis,:,:,:]\n",
        "\n",
        "    episodeReward = 0\n",
        "    epidoseLoss = 0\n",
        "    episodeNewVisited = 0\n",
        "    episodePenalty = 0\n",
        "    agent_episode_reward = [0] * CONST.NUM_AGENTS\n",
        "\n",
        "    for step in range(LEN_EPISODES):\n",
        "        timestep += 1\n",
        "\n",
        "        # render environment after taking a step\n",
        "        keyPress = 1\n",
        "\n",
        "        # if keyPress == 1:\n",
        "            # env.render()\n",
        "\n",
        "        # TODO save video\n",
        "        if episode % 500 in range(10, 15) and step % 4 == 0:\n",
        "            env.save2Vid(episode, step)\n",
        "        #        a = t()\n",
        "        # Get agent actions\n",
        "        # =============================================================================\n",
        "        #         for i in range(CONST.NUM_AGENTS):\n",
        "        #             action = rlAgent.policy.act(curState[i], memory,i)\n",
        "        #             aActions.append(action)\n",
        "        # =============================================================================\n",
        "        aActions = rlAgent.policy_old.act(curState, memory, CONST.NUM_AGENTS)\n",
        "        #        b = t()\n",
        "        #        print(\"step: \", round(b-a,2))\n",
        "\n",
        "        # do actions\n",
        "\n",
        "        newRawState = env.step(aActions[0])\n",
        "        #        newRawState  = env.step([0])\n",
        "        # agent_pos_list, current_map_state, local_heatmap_list, minimap_list, local_reward_list, shared_reward, done = newRawState\n",
        "        current_map_state, shared_reward, done, _ = newRawState\n",
        "\n",
        "        if step == LEN_EPISODES - 1:\n",
        "            done = True\n",
        "\n",
        "        for agent_index in range(CONST.NUM_AGENTS):\n",
        "            if CONST.isSharedReward:\n",
        "                memory.rewards.append(shared_reward)\n",
        "            else:\n",
        "                memory.rewards.append(local_reward_list[agent_index])\n",
        "            memory.is_terminals.append(done)\n",
        "\n",
        "        # update nextState\n",
        "        # newState = rlAgent.formatInput(newRawState)\n",
        "        newState = np.transpose(current_map_state, (2,0,1))[np.newaxis,:,:,:]\n",
        "\n",
        "        if timestep % UPDATE_TIMESTEP == 0:\n",
        "            loss = rlAgent.update(memory)\n",
        "            memory.clear_memory()\n",
        "            timestep = 0\n",
        "\n",
        "        # print('CHECK:', timestep, len(memory.states))\n",
        "        # record history\n",
        "\n",
        "        for i in range(CONST.NUM_AGENTS):\n",
        "            if CONST.isSharedReward:\n",
        "                agent_episode_reward[i] += shared_reward\n",
        "            else:\n",
        "                agent_episode_reward[i] += local_reward_list[i]\n",
        "        episodeReward += shared_reward\n",
        "        #        print(shared_reward, step)\n",
        "        # set current state for next step\n",
        "        curState = newState\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # post episode\n",
        "\n",
        "    # Record history\n",
        "    reward_history.append(episodeReward)\n",
        "\n",
        "    for i in range(CONST.NUM_AGENTS):\n",
        "        agent_history_dict[i].append((agent_episode_reward[i]))\n",
        "\n",
        "    # You may want to plot periodically instead of after every episode\n",
        "    # Otherwise, things will slow\n",
        "    rlAgent.summaryWriter_addMetrics(episode, loss, reward_history, agent_history_dict, LEN_EPISODES)\n",
        "    if episode % 50 == 0:\n",
        "        rlAgent.saveModel(\"checkpoints\")\n",
        "\n",
        "    if episode % 1000 == 0:\n",
        "        rlAgent.saveModel(\"checkpoints\", True, episode)\n",
        "\n",
        "rlAgent.saveModel(\"checkpoints\")\n",
        "env.out.release()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ee9c10dd7a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mUPDATE_TIMESTEP\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrlAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PPO_agent.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, memory)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Evaluating old actions and values :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mlogprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# Finding the ratio (pi_theta / pi_theta__old):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mold_logprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PPO_agent.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mdist_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PPO_agent.py\u001b[0m in \u001b[0;36mvalue_layer\u001b[0;34m(self, x1)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m#        x = torch.cat((x,x2), dim = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 14.73 GiB total capacity; 11.31 GiB already allocated; 2.37 GiB free; 11.32 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "datqfj45jish",
        "outputId": "226734bc-16e4-472d-fa7d-7fced61f1219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "timestep, len(memory.states)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZYNMkjhjtjN"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4gSz5lrlD23",
        "outputId": "74537b19-0605-4adb-a1ed-f44ce6446376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ9s9WxilQUF"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkFGNVIHE6i6",
        "outputId": "1bac83a4-bf64-4497-f973-4bb82fcd2e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(247, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9ojvkLGFGyc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}